{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문제 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 로지스틱 회귀에 대해 선형회귀와 비교하여 설명하세요.\n",
    "#### (1)-1 로지스틱 회귀를 사용하면 좋은 데이터의 종류?\n",
    "### (2) 회귀 트리의 예측 과정을 설명하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) 로지스틱 회귀는 선형회귀와 달리 sigmoid function을 이용하여 최적의 sigmoid function을 도출하는 회귀이다. 선형회귀는 종속변수의 범위가 정해지지 않은 반면, 로지스틱 회귀는 종속변수의 범위가 0~1로 정해진다. 따라서 이를 확률로 해석할 수 있고, classification의 문제에서 적용하기에 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) feature의 균일도를 반영하여 분할하고, 리프노드에 소속된 데이터 값의 평균값을 구해서 최종적으로 리프 노드에 결정 값으로 할당한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문제 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Ridge (L2) Regression을 설명하세요. (참고 링크: https://youtu.be/Q81RR3yKn30)\n",
    "### (2) Lasso (L1) Regression을 설명하세요. (참고 링크: https://youtu.be/NGf0voTMlcs)\n",
    "### (3) Ridge (L2) Regression과 Lasso (L1) Regression의 차이점을 서술하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ridge Regression 은 L2 규제를 부여하는 방식으로, weight값의 제곱에 대해 패널티를 부여하는 방식이다.\n",
    "2. Lasso Regression 은 L! 규제를 부여하는 방식으로, weight값의 절댓값에 대해 패널티를 부여하는 방식이다.\n",
    "3. Lasso Regression은 영향력이 작은 weight의 값을 0으로 만드는 방향으로 움직이는 반면, Ridge Regression은 전체적으로 고른 weight 분포 값을 만드는 방향으로 움직인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문제 3 \n",
    "## 다음 문제 과정에 필요한 코드를 완성하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### (1) train.csv 파일 불러오기\n",
    "\n",
    "### (2) 문자열을 datetime 타입으로 변경. \n",
    "\n",
    "### (3) datetime 타입에서 년, 월, 일, 시간 추출\n",
    "*lambda를 이용해서 추출\n",
    "ex) 파일[열이름]=파일.datetime.apply(lambda x: x.year)\n",
    "\n",
    "### (4) 'datetime','casual','registered''temp''atemp' 5개의 열은 제외하기\n",
    "*drop 함수 이용\n",
    "\n",
    "### (5) RMSLE, RMSE, MAE 값 구하기 \n",
    "답: RMSLE: 1.221, RMSE: 149.317, MAE: 111.420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-(1)\n",
    "train = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-(2)\n",
    "train.datetime = pd.to_datetime(train.datetime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-(3)\n",
    "train[\"year\"]= train.datetime.apply(lambda x : x.year)\n",
    "train[\"month\"]  = train.datetime.apply(lambda x : x.month)\n",
    "train[\"day\"] = train.datetime.apply(lambda x : x.day)\n",
    "train[\"hour\"] = train.datetime.apply(lambda x : x.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-(4)\n",
    "drop_columns = ['datetime','casual','registered', 'temp', 'atemp']\n",
    "train.drop(drop_columns, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE : 1.2213726796860824, RMSE : 149.31653208184704, MAE : 111.42038771242213\n"
     ]
    }
   ],
   "source": [
    "#3-(5)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def rmsle(y, pred):\n",
    "    log_y = np.log1p(y)\n",
    "    log_pred = np.log1p(pred)\n",
    "    squared_error = (log_y - log_pred)**2\n",
    "    rmsle = np.sqrt(np.mean(squared_error))\n",
    "    \n",
    "    return rmsle\n",
    "\n",
    "def rmse(y, pred):\n",
    "    return np.sqrt(mean_squared_error(y, pred))\n",
    "\n",
    "def evaluate_regr(y,pred):\n",
    "    rmsle_val = rmsle(y,pred)\n",
    "    rmse_val = rmse(y,pred)\n",
    "    \n",
    "    mae_val = mean_absolute_error(y,pred)\n",
    "    print(f\"RMSLE : {rmsle_val}, RMSE : {rmse_val}, MAE : {mae_val}\")\n",
    "\n",
    "X_features = train.drop([\"count\"], axis=1)\n",
    "y_target = train[\"count\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_target, test_size = 0.3, random_state=0)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "evaluate_regr(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문제 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 3번의 결과, 예측오류가 크다고 볼 수 있습니다. 그 이유는? \n",
    "\n",
    "### (2) 예측오류를 줄이기위한 대표적인 방법으로 정규화가 있습니다. 아래 순서대로 코드를 완성하세요.\n",
    "   \n",
    "       -실제값과 예측값의 차이 확인하라. 오류값이 가장 큰 순으로 7개를 나열하세요.\n",
    "       -결과 값이 정규분포로 되어있는지 그래프를 확인하세요.\n",
    "       -정규분포가 아닐 경우, log1p()를 활용하여 정규화하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) 대여횟수에 비해 예측오류가 크기 때문에 예측 오류가 크다고 볼수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      real_count  predicted_count   diff\n",
      "1181         891            293.0  598.0\n",
      "1038         873            298.0  575.0\n",
      "2314         766            196.0  570.0\n",
      "1618         890            322.0  568.0\n",
      "3197         694            127.0  567.0\n",
      "2277         813            248.0  565.0\n",
      "1029         901            349.0  552.0\n"
     ]
    }
   ],
   "source": [
    "def get_top_error_data(y_test, pred, n_tops = 7):\n",
    "    result_df = pd.DataFrame(y_test.values, columns = [\"real_count\"])\n",
    "    result_df[\"predicted_count\"] = np.round(pred)\n",
    "    result_df[\"diff\"] = np.abs(result_df[\"real_count\"]-result_df[\"predicted_count\"])\n",
    "    \n",
    "    print(result_df.sort_values([\"diff\"], ascending=False)[:n_tops])\n",
    "    \n",
    "get_top_error_data(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 105.,  276.,  571.,  636.,  762.,  961., 1613., 2657., 2437.,\n",
       "         868.]),\n",
       " array([1.        , 1.68844867, 2.37689733, 3.065346  , 3.75379466,\n",
       "        4.44224333, 5.13069199, 5.81914066, 6.50758932, 7.19603799,\n",
       "        7.88448665]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(y_target)\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(1+np.log(y_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위 4번의 내용을 반영하여 다시 학습 후 평가수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE : 1.075267073128036, RMSE : 176.8681231562364, MAE : 119.58789017846381\n"
     ]
    }
   ],
   "source": [
    "# 타겟 컬럼인 count 값을 log1p 로 Log 변환\n",
    "y_target_log = np.log1p(y_target)\n",
    "\n",
    "# 로그 변환된 y_target_log를 반영하여 학습/테스트 데이터 셋 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_target_log, test_size=0.3, random_state=0)\n",
    "lr_reg = LinearRegression()\n",
    "lr_reg.fit(X_train, y_train)\n",
    "pred = lr_reg.predict(X_test)\n",
    "\n",
    "# 테스트 데이터 셋의 Target 값은 Log 변환되었으므로 다시 expm1를 이용하여 원래 scale로 변환\n",
    "y_test_exp = np.expm1(y_test)\n",
    "\n",
    "# 예측 값 역시 Log 변환된 타겟 기반으로 학습되어 예측되었으므로 다시 exmpl으로 scale변환\n",
    "pred_exp = np.expm1(pred)\n",
    "\n",
    "evaluate_regr(y_test_exp ,pred_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문제 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) RMSLE 오류는 줄었으나, RMSE는 늘어나서 피처를 인코딩하려고 할 때 쓰이는 방법과 효과는? \n",
    "### (2) year, month, hour, season, weather 칼럼을 인코딩하고 예측성능을 향상시키세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one-hot encoding을 통해 카테고리형 데이터를 one-hot 칼럼으로 변환시킴으로써 카테고리형 데이터를 모델이 순서가 있는 데이터로 오해하지 않도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features_onehot = pd.get_dummies(X_features, columns = [\"year\",\"month\",\"hour\",\"season\",\"weather\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE : 0.5976961488647843, RMSE : 97.94627258693815, MAE : 64.0311455743079\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features_onehot, y_target_log, test_size = 0.3, random_state = 0)\n",
    "\n",
    "def get_model_predict(model, X_train, X_test, y_train, y_test, is_expm1=False):\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    \n",
    "    if is_expm1:\n",
    "        y_test = np.expm1(y_test)\n",
    "        pred = np.expm1(pred)\n",
    "        \n",
    "    evaluate_regr(y_test , pred)\n",
    "    \n",
    "model = LinearRegression()\n",
    "\n",
    "get_model_predict(model, X_train, X_test, y_train, y_test, is_expm1=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
