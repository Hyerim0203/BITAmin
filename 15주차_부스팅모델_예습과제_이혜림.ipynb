{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost\n",
    "- 이진분류에서만 사용가능 -> y의 값 : -1, 1\n",
    "- 그 전단계 위원회의 성능을 보완하여 위원회에 개별 모형을 추가하는 식으로 위원회 성능 보완\n",
    "- 최종 예측시에는 개별 약 분류기들에 각각 가중치를 적용, 조합하여 얻음  \n",
    "- 여러 개별 후보들 : 모든 feature \n",
    "- 그 중에서 위원회에 넣을 개별 모형을 선별하는 방법\n",
    "    1. 틀리게 예측한 데이터의 가중치를 합한 값을 손실함수 L로 사용 -> 이것을 최소화하는 모형이 다음 모형으로 선택\n",
    "  \n",
    "- 틀린 데이터에 대해 적용할 가중치 = > ln((1-e)/e)\n",
    "- 처음에 모든 data에 대해 같은 weight 값 -> 1/데이터 개수의 값을 가짐.\n",
    "https://velog.io/@sangyeop/AdaBoost-%ED%95%9C-%EB%88%88%EC%97%90-%EC%95%8C%EC%95%84%EB%B3%B4%EA%B8%B0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost\n",
    "- 분류 및 회귀 모든 문제에 사용 가능\n",
    "- 현재까지 학습된 모델의 약점을 드러내는 역할을 하고, 다음 모델이 그걸 중점적으로 보완해서 성능을 Boosting 하는 방법\n",
    "- 분류 및 회귀 문제에 상관없이 회귀분석 모형을 사용.\n",
    "- 맨 처음 모든 데이터의 예측값으로 실제 값의 모든 것의 평균으로 설정. -> 잔차를 구하고 잔차를 기준으로 decision tree 생성.\n",
    "- 잔차에 learning rate를 곱하여서 예측값을 update, -> overfitting을 방지\n",
    "- 전체 데이터에 대해 모든 잔차를 다 업데이트하고, 이를 기반으로 새로운 tree 생성\n",
    "https://dailyheumsi.tistory.com/116"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost\n",
    "- GBM 기반의 알고리즘으로 분산 환경에서도 실행할 수 있도록 구현해놓은 라이브러리\n",
    "- XGboost 장점\n",
    "    - 뛰어난 예측 성능\n",
    "    - GBM 대비 빠른 수행 시간\n",
    "    - 과적합 규제\n",
    "    - Tree pruning\n",
    "    - 자체 내장된 교차 검증\n",
    "    - 결손값 자체 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_human_dataset():\n",
    "    feature_name_df = pd.read_csv(\"C:/Users/이혜림/Desktop/Bita5/9주차/UCI HAR Dataset/human_activity/features.txt\",\n",
    "                                 sep=\"\\s+\", header=None, names = [\"column_index\",\"column_name\"])\n",
    "    \n",
    "    new_feature_name_df = get_new_feature_name_df(feature_name_df)\n",
    "    \n",
    "    feature_name = new_feature_name_df.iloc[:.1].values.tolist()\n",
    "    # 피러명을 열로 부여하기 위해 리스트 객체로 변화\n",
    "    \n",
    "    X_train=pd.read_csv(\"C:/Users/이혜림/Desktop/Bita5/9주차/UCI HAR Dataset/human_activity/X_train.txt\",\n",
    "                        sep=\"\\s+\", names=feature_name)\n",
    "    X_test = pd.read_csv(\"C:/Users/이혜림/Desktop/Bita5/9주차/UCI HAR Dataset/human_activity/X_test.txt\",\n",
    "                         sep=\"\\s+\", names=feature_name)\n",
    "    y_train = pd.read_csv(\"C:/Users/이혜림/Desktop/Bita5/9주차/UCI HAR Dataset/human_activity/y_train.txt\",\n",
    "                          sep=\"\\s+\", header=None, names=[\"action\"])\n",
    "    y_test = pd.read_csv(\"C:/Users/이혜림/Desktop/Bita5/9주차/UCI HAR Dataset/human_activity/y_test.txt\",\n",
    "                         sep=\"\\s+\", header=None, names=[\"action\"])\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_human_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()\n",
    "\n",
    "# GBM 수행 시간 측정을 위한 시작시간 설정\n",
    "start_time = time.time()\n",
    "\n",
    "# 예시 데이터셋 불러오기\n",
    "gb_clf = GradientBoostingClassifier(random_state=0)\n",
    "gb_clf.fit(X_train, y_train.values)\n",
    "gb_pred = gb_clf.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "\n",
    "print(gb_accuracy)\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GrdiSearchCV\n",
    "\n",
    "params = {\"n_estimators\":[10,20],\"learning_rate\":[0.05,0.1]}\n",
    "\n",
    "grid_cv = GridSearchCV(gb_clf, param_grid=params, cv=2, verbose=1)\n",
    "grid_cv.fit(X_train, y_train)\n",
    "\n",
    "print(grid_cv.best_params_)\n",
    "print(grid_cv.best_scrore_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV를 이용해 최적으로 학습된 estimators로 예측 수행\n",
    "gb_pred = grid_cv.best_estimator_.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "print(gb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "X_features = dataset.data\n",
    "y_label =dataset.target\n",
    "\n",
    "cancer_df = pd.DataFrame(data=X_features, columns=dataset.feature_names)\n",
    "cancer_df[\"target\"]=y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X_features,y_label,\n",
    "                                                 test_size=0.2, random_state=156)\n",
    "\n",
    "# Dmatrix : numpy 입력 파라미터를 받아서 만들어지는 XGBoost만의 전용 데이터셋\n",
    "# pandas의 데이터셋이라면 numpy의 데이터셋으로 변경해주는 것이 필요함\n",
    "dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(data=X_test, label=y_test)\n",
    "\n",
    "params = {\"max_depth\":3, \"eta\":0.1,\"objective\":\"binary:logistic\",\n",
    "         \"eval_metric\":\"logloss\"}\n",
    "num_rounds = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wlist = [(dtrain,\"train\"),(dtest,\"eval\")]\n",
    "\n",
    "# 하이퍼 파라미터와 early stopping 파라미터를 train()함수의 파라미터로 전달\n",
    "xgb_model = xgb.train(params=params, dtrain=dtrain, num_boost_round=num_rounds,\n",
    "                     early_stopping_rounds=100, evals=wlist)\n",
    "\n",
    "# eval 파라미터에 학습 데이터 셋과 eval 데이터 셋을 명시해주면 eval 데이터셋에 대해\n",
    "# 평가를 수행하면서 조기 중단 적용 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = xgb_model.predict(dtest)\n",
    "print(np.round(pred_probs[:10],3))\n",
    "\n",
    "preds = [1 if x>0.5 else 0 for x in pred_probs]\n",
    "print(preds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion=confusion_matrix(y_test,pred)\n",
    "    accuracy = accuracy_score(y_test,pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    \n",
    "    # ROC-AUC 추가\n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,12))\n",
    "plot_importance(xgb_mdel, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_wrapper = XGBClassifier(n_estimaotrs=400, learning_rate = 0.1, max_depth=3)\n",
    "xgb_wrapper.fit(X_train, y_train)\n",
    "w_preds = xgb_wrapper.predict(X_test)\n",
    "w_pred_proba = xgb_wrapper.predict_proba(X_test)[:,1]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion=confusion_matrix(y_test,pred)\n",
    "    accuracy = accuracy_score(y_test,pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    \n",
    "    # ROC-AUC 추가\n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_wrapper = XGBClassifier(n_estimaotrs=400, learning_rate = 0.1, max_depth=3)\n",
    "xgb_wrapper.fit(X_train, y_train, early_stopping_rounds=100)\n",
    "w_preds = xgb_wrapper.predict(X_test)\n",
    "w_pred_proba = xgb_wrapper.predict_proba(X_test)[:,1]\n",
    "\n",
    "# early stooping roudns -> 100번의 반복동안 더이상 성능 평가 지수가 향상되지 않는다면\n",
    "# 반복을 멈춤\n",
    "\n",
    "# 만약 100보다 더 적은 숫자로 하면 성능 저하가 많이 일어날 가능성이 o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_wrapper = XGBClassifier(n_estimaotrs=400, learning_rate = 0.1, max_depth=3)\n",
    "xgb_wrapper.fit(X_train, y_train)\n",
    "w_preds = xgb_wrapper.predict(X_test)\n",
    "w_pred_proba = xgb_wrapper.predict_proba(X_test)[:,1]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion=confusion_matrix(y_test,pred)\n",
    "    accuracy = accuracy_score(y_test,pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    \n",
    "    # ROC-AUC 추가\n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "ftr = dataset.data\n",
    "target = dataset.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ftr, target, test_size = 0.2,\n",
    "                                                   random_state = 156)\n",
    "\n",
    "# 트리 개수는 400개로 지정\n",
    "lgbm_wrapper = LGMBClassifier(n_estimators=400)\n",
    "\n",
    "# early stopping 기능\n",
    "evals = [(X_test, y_test)]\n",
    "lgbm_wrapper.fit(X_train,y_train, early_stopping_rounds = 100, eval_metric = \"logloss\",\n",
    "                eval_set=evals, verbose=True)\n",
    "\n",
    "preds = lgbm_wrapper.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion=confusion_matrix(y_test,pred)\n",
    "    accuracy = accuracy_score(y_test,pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    \n",
    "    # ROC-AUC 추가\n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
